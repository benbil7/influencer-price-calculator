\
import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import re

st.set_page_config(page_title="Influencer Price Calculator", page_icon="ğŸ’¸", layout="wide")
st.title("ğŸ’¸ Influencer Price Calculator")
st.caption("CSVë¥¼ ì—…ë¡œë“œí•˜ê³ , ì…ë ¥ê°’ìœ¼ë¡œ ì ì • ë‹¨ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (RandomForest íšŒê·€)")

# -------------------- Utilities --------------------
EXPECTED = [
    "Influencer","Followers","Tier","Median of 20-View","Median of 20-Save",
    "US Viewer %","Influencer Quoted Price","Contracted Price"
]

CANON = {
    "influencer":"Influencer",
    "followers":"Followers",
    "tier":"Tier",
    "median of 20-view":"Median of 20-View",
    "median of 20-save":"Median of 20-Save",
    "us viewer %":"US Viewer %",
    "us viewer%":"US Viewer %",
    "us %":"US Viewer %",
    "influencer quoted price":"Influencer Quoted Price",
    "quoted price":"Influencer Quoted Price",
    "contracted price":"Contracted Price",
    "final price":"Contracted Price"
}

# ì›í•˜ëŠ” Tier ìˆœì„œ (UI ë° ì •ë ¬ì— ì‚¬ìš©)
TIER_ORDER = ["Nano", "Micro", "Mid", "Macro", "Mega"]

def norm(s: str) -> str:
    s = re.sub(r"\s+", " ", str(s).strip())
    s = s.replace("â€‘","-").replace("â€“","-")  # weird dashes
    return s

def clean_numeric(x):
    if pd.isna(x):
        return None
    x = str(x)
    x = x.replace(",", "").replace("$", "").replace("%", "").strip()
    x = x.replace("USD","").strip()
    try:
        return float(x)
    except ValueError:
        return None

@st.cache_data(show_spinner=False)
def load_csv(file) -> pd.DataFrame:
    # Try common encodings
    for enc in ["utf-8", "cp949", "ISO-8859-1"]:
        try:
            df = pd.read_csv(file, encoding=enc)
            # normalize headers
            new_cols = []
            for c in df.columns:
                c2 = norm(c)
                key = c2.lower()
                new_cols.append(CANON.get(key, c2))
            df.columns = new_cols
            return df
        except Exception:
            file.seek(0)
            continue
    st.error("CSV ì¸ì½”ë”©ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. UTF-8/CP949ë¡œ ì €ì¥í•´ì„œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    st.stop()

@st.cache_resource(show_spinner=False)
def train_model(df: pd.DataFrame):
    # ensure essential columns exist
    missing = [c for c in ["Tier","Followers","Median of 20-View","Median of 20-Save","US Viewer %","Contracted Price"] if c not in df.columns]
    if missing:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}. CSV í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”. (ì˜ˆìƒ í—¤ë” ì˜ˆ: {EXPECTED})")
        st.stop()

    # numeric cleanup
    for col in ["Followers","Median of 20-View","Median of 20-Save","US Viewer %","Influencer Quoted Price","Contracted Price"]:
        if col in df.columns:
            df[col] = df[col].apply(clean_numeric)

    # filter to contracted
    mask = df["Contracted Price"].notna()
    if not mask.any():
        st.error("ê³„ì•½ ë‹¨ê°€(Contracted Price)ê°€ ì¡´ì¬í•˜ëŠ” í–‰ì´ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    df_train = df.loc[mask, ["Followers","Median of 20-View","Median of 20-Save","US Viewer %","Tier","Contracted Price"]].dropna()
    if len(df_train) < 30:
        st.warning("í•™ìŠµ ê°€ëŠ¥í•œ í‘œë³¸ì´ 30ê±´ ë¯¸ë§Œì…ë‹ˆë‹¤. ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆì–´ìš”.")

    X = df_train[["Followers","Median of 20-View","Median of 20-Save","US Viewer %","Tier"]]
    y = df_train["Contracted Price"]

    preprocessor = ColumnTransformer(
        transformers=[("cat", OneHotEncoder(handle_unknown="ignore"), ["Tier"])],
        remainder="passthrough"
    )

    model = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("regressor", RandomForestRegressor(n_estimators=400, random_state=42))
    ])

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model.fit(X_train, y_train)
    r2 = model.score(X_test, y_test)
    return model, r2, df

def predict_price(model, row: dict):
    input_df = pd.DataFrame([row])
    pred = float(model.predict(input_df)[0])
    return pred

def verdict(pred, quoted, tol=0.2):
    if quoted is None or (isinstance(quoted, float) and np.isnan(quoted)):
        return "No Quote", "ì œì•ˆ ë‹¨ê°€ê°€ ì—†ìŠµë‹ˆë‹¤."
    if quoted > pred * (1 + tol):
        return "Overpriced", f"ì œì•ˆê°€(${quoted:,.0f})ê°€ ì˜ˆìƒì¹˜(${pred:,.0f})ë³´ë‹¤ {int(tol*100)}% ì´ìƒ ë†’ìŒ"
    elif quoted < pred * (1 - tol):
        return "Underpriced", f"ì œì•ˆê°€(${quoted:,.0f})ê°€ ì˜ˆìƒì¹˜(${pred:,.0f})ë³´ë‹¤ {int(tol*100)}% ì´ìƒ ë‚®ìŒ"
    else:
        return "Fair", f"ì œì•ˆê°€(${quoted:,.0f})ê°€ ì˜ˆìƒì¹˜(${pred:,.0f}) Â±{int(tol*100)}% ì´ë‚´"

# -------------------- Sidebar --------------------
with st.sidebar:
    st.header("1) CSV ì—…ë¡œë“œ")
    file = st.file_uploader("influencer data.csv ì—…ë¡œë“œ", type=["csv"])
    tol_pct = st.slider("íŒì • í—ˆìš© ë²”ìœ„ (Â±%)", 5, 40, 20, step=5)
    st.caption("ì˜ˆ: 20% â†’ ì˜ˆìƒì¹˜ ê¸°ì¤€ Â±20% ì´ë‚´ë©´ Fair")

if not file:
    st.info("ì¢Œì¸¡ì—ì„œ CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. ê¶Œì¥ ì»¬ëŸ¼: " + ", ".join(EXPECTED))
    st.stop()

df_raw = load_csv(file)
model, r2, df_clean = train_model(df_raw)
st.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ Â· í…ŒìŠ¤íŠ¸ RÂ² = {r2:.2f}")

# -------------------- Tabs --------------------
tab1, tab2 = st.tabs(["ğŸ”¢ ë‹¨ê±´ ê³„ì‚°ê¸°", "ğŸ“¦ ì¼ê´„ íŒì •"])

with tab1:
    st.subheader("ë‹¨ê±´ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡")
    c1, c2, c3 = st.columns(3)
    with c1:
        # Tier ë“œë¡­ë‹¤ìš´: ì›í•˜ëŠ” ìˆœì„œ ìœ ì§€
        present_tiers = [t for t in TIER_ORDER if t in df_clean["Tier"].dropna().unique().tolist()]
        if not present_tiers:
            present_tiers = sorted(df_clean["Tier"].dropna().unique().tolist())
        tier = st.selectbox("Tier", options=present_tiers, index=0)

        followers = st.number_input("Followers", min_value=0, value=20000, step=100)
    with c2:
        median_view = st.number_input("Median of 20-View", min_value=0, value=3000, step=10)
        median_save = st.number_input("Median of 20-Save", min_value=0, value=20, step=1)
    with c3:
        us_pct = st.number_input("US Viewer %", min_value=0, max_value=100, value=40, step=1)
        quoted = st.number_input("Influencer Quoted Price ($)", min_value=0, value=500, step=10)

    if st.button("ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
        row = {
            "Followers": followers,
            "Median of 20-View": median_view,
            "Median of 20-Save": median_save,
            "US Viewer %": us_pct,
            "Tier": tier
        }
        pred = predict_price(model, row)
        v, reason = verdict(pred, quoted, tol=tol_pct/100.0)

        st.metric(label="ì˜ˆìƒ ë‹¨ê°€ (USD)", value=f"${pred:,.0f}")
        st.metric(label="ì œì•ˆ ë‹¨ê°€ (USD)", value=f"${quoted:,.0f}")
        st.markdown(f"**íŒì •:** {v}")
        st.caption(reason)

with tab2:
    st.subheader("CSV ì¼ê´„ íŒì •")
    df = df_clean.copy()

    # compute predictions for rows with enough data
    needed = ["Followers","Median of 20-View","Median of 20-Save","US Viewer %","Tier"]
    missing_mask = df[needed].isna().any(axis=1)
    usable = df[~missing_mask].copy()

    # clean quoted
    if "Influencer Quoted Price" in usable.columns:
        usable["Influencer Quoted Price"] = usable["Influencer Quoted Price"].apply(clean_numeric)
    else:
        usable["Influencer Quoted Price"] = np.nan

    if usable.empty:
        st.warning("ì˜ˆì¸¡ì— í•„ìš”í•œ ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ê°€ ë§ì•„ ì¼ê´„ íŒì •ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        preds, verdicts, reasons = [], [], []
        tol = tol_pct/100.0
        for _, r in usable.iterrows():
            row = {
                "Followers": r["Followers"],
                "Median of 20-View": r["Median of 20-View"],
                "Median of 20-Save": r["Median of 20-Save"],
                "US Viewer %": r["US Viewer %"],
                "Tier": r["Tier"]
            }
            pred = predict_price(model, row)
            q = r.get("Influencer Quoted Price", np.nan)
            v, reason = verdict(pred, q, tol=tol)
            preds.append(pred); verdicts.append(v); reasons.append(reason)

        usable["Predicted Price"] = np.round(preds, 2)
        usable["Verdict"] = verdicts
        usable["Reason"] = reasons

        # Tier ìˆœì„œë¡œ ì •ë ¬(ìˆì„ ë•Œë§Œ)
        cat_type = pd.api.types.CategoricalDtype(categories=TIER_ORDER, ordered=True)
        if "Tier" in usable.columns:
            try:
                usable["Tier"] = usable["Tier"].astype(cat_type)
                usable = usable.sort_values(["Tier","Followers"])
            except Exception:
                pass

        st.dataframe(
            usable[["Influencer","Tier","Followers","Median of 20-View","Influencer Quoted Price","Predicted Price","Verdict","Reason"]].head(200),
            use_container_width=True
        )
        # Download
        csv_bytes = usable.to_csv(index=False).encode("utf-8")
        st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="priced_influencers.csv", mime="text/csv")

st.divider()
st.caption("â€» ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì•±ì…ë‹ˆë‹¤. ì—…ë¡œë“œí•œ íŒŒì¼ì€ ë¸Œë¼ìš°ì €/PC ë‚´ì—ì„œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
